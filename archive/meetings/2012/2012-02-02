---+ Meeting between Executive Team and OSG Software Coordinator, 2-Feb-2012

I last met directly with the Executive Team on [[SoftwareTeam.2011-09-01][September 1, 2011]].

---++ 1.0 Some recent events

   1. The initial RPM transition has been completed. [[Documentation.Release3.ReleaseNotes][Release Notes]]<br>We have shipped the CE, SE (Bestman/Xrootd/HDFS), RSV, Client, Worker Node Client, VOMS, and glexec.
   2. Alex Sim and his team are no longer supporting Bestman 2 for OSG as of December, 2011. 
      * The lastest version released by Alex was tested by us and is now in our production release.
      * Neha Sharma is the primary support in OSG and Doug Strain is the backup. 
      * We have settled on the process by which we'll maintain the Bestman source code while still collaborating with the SRM team at LBNL. (They will host the source code and provide limited guidance on proposed changes.) 
      * We have made updates to Bestman since it was released. 

---++ 2.0 Major upcoming work

*Big picture for the year:* While we have completed our initial RPM release, there is still a lot to do. Much of our work this year will be in filling the holes and smoothing out the rough patches to make our new style of packaging meet the needs of our users. Some specific examples follow.

---+++ 2.1 Support for sites and VOs as they deploy the new OSG Software 3 release.

We will provide support and assistance as sites upgrade to the new OSG Software 3 release. To date, the support load has not increased as compared to pre-release levels, but I believe it will increase.

We know that the new RPM-based OSG Software 3 has been deployed at:

   * SMU_HPC
   * !GridUNESP_CENTRAL
   * RENCI-Blueberry
   * CMS Tier2 at Wisconsin (worker nodes, HDFS, Xrootd, SRM & !GridFTP, but not yet the CE)
   * Nebraska: Firefly, Red & Prairiefire (7 Compute Elements total)

Representatives from CMS and ATLAS have told me that they have asked their sites to update by April 2012. So far we have not had much feedback from individual sites other than SMU and RENCI.

Previously, our support model was not well organized and not well-suited to a distributed team. In order to provide quality support as people adopt the new release, we must improve it. I have written a [[SoftwareTeam.TransitionToGocTicket][plan for how we will do support]]. The Operations and Software Teams have agreed to the plan. 

---+++ 2.2 Scientific Linux 6 support.

CMS has requested that we support the worker node client on Scientific Linux 6 by the end of February, 2012, and ATLAS has requested the same for the end of March. [[http://jira.opensciencegrid.org/browse/REQUESTS-16][REQUESTS-16]]

We are finalizing our [[SoftwareTeam.SL6Support][plan for Scientific Linux 6 support]] by the end of this week. Derek Weitzel has contributed a proof-of-concept of some aspects of the plan.

---+++ 2.3 Adding missing software 

We did not package all software as part of our initial transition. There are three pieces that are missing:

   1. *GUMS* [[http://jira.opensciencegrid.org/browse/REQUESTS-32][REQUESTS-32]] We are working on this now. It will require significant testing and evaluation. We will collect requirements from !FermiGrid (they use GUMS heavily) and test within the OSG Evaluation Group. We do not yet have a timeline. We expect a new release of GUMS from John Hover by the end of February. If testing goes well, we can release by the end of March, but this is contingent upon successful testing.
   1. *CREAM* [[http://jira.opensciencegrid.org/browse/REQUESTS-33][REQUESTS-33]] ATLAS has requested !CREAM support by the end of September 2012. We will develop a plan for this work soon. 
   1. *Gratia Collector* [[http://jira.opensciencegrid.org/browse/REQUESTS-34][REQUESTS-34]] We will work with Tanya Levshina (Gratia/Fermilab) to package the Gratia Collector. There is not yet a plan for this work.


---+++ 2.4 SHA-2 transition

I've taken over the SHA-2 transition from the security team because it is mostly a software issue. The security team will provide advice as needed.

As of January 2012, all certificates in use in OSG (CA, host, user, and proxy) certificates use SHA-1 or MD5 as their signing algorithm. In the near future (where "near" is being defined), the Certificate Authorities will begin using SHA-2 as their signing algorithm. To ensure we are ready, we need to verify that all software we provide works with MD5, SHA-1 and SHA-2. If any software is not ready, it must be updated. If we are unable to update, we need to find workarounds or delay the transition to SHA-2.

Our biggest known problem is jGlobus, which is used by dCache and Bestman. The new version of jGlobus (currently in beta) support SHA-2 but does not support legacy or pre-RFC proxies and may not support httpg. I am organizing a meeting with developers from Globus, Bestman, and dCache to understand our path forward. This meeting should happen within the next few business days (trying to settle a time as I write this text).

The [[SoftwareTeam.Sha2Support][SHA-2 plan is being developed]]. It cannot be finalized until we understand the path we will take with jGlobus.

---+++ 2.5 Understanding effort

Latest effort data (through December 2011): [[%ATTACHURL%/VDTEffort.2012.01.xlsx][VDTEffort.2012.01.xlsx]]

It will be updated for January shortly. (It takes a couple of days after the end of the month to get new data.)

I've been collecting effort data for the last several months. Each person has provided a % of their working time (vacation is not counted) per month broken down by the project they are working on. It has become clear to me that I do not have the right data. 

I'm working with Brooklin Gore from the UW-Madison to collect the right data. (With valuable advice from the ABCD team.) We are beginning not with the data, but by asking the right questions then deciding what data we will collect in order to answer those questions. I believe that (if I pick the right questions) you care more about the answers to the questions rather than the underlying raw data. 

As a first pass, I think these are the of questions I wish to be able to answer. Do you agree? Are these the kinds of effort-related questions you would like to be able to answer?

   * How much effort is being spent on the OSG Software Team? (Not how much has been allocated in the SOW, but how much did we actually see?)
   * How much effort did it take to accomplish completed project X? 
   * If asked to do project Y, what other projects will get less effort? 
   * What effort do I need to sustain the team? (And what size does does my team need to be?)
   * How much time do we spend on software development vs. maintenance/packaging vs support vs. documentation?

While I have not fleshed out the method I will use to collect the underlying data, it is likely that I will collect hours (not percent time) on a weekly basis (not monthly). I want to be careful to get the right tradeoff in the granularity of the data vs. not imposing too high an overhead in collecting the data. 

---+++ 2.6 Usability testing

We will be doing usability testing for BOSCO, the campus grid software. [[http://jira.opensciencegrid.org/browse/REQUESTS-30][REQUESTS-30]] We are working on a plan now. The goal is to do this before the initial release of BOSCO in the second quarter (May/June) of this year.

---++ 3.0 User requests

At the beginning of January, I asked VOs across OSG to provide request for what they need from the OSG Software Group for the next six to twelve months. Almost all of the requests were from CMS and ATLAS. Most of the requests were listed above, but the complete list follows:

---+++ 3.1 CMS requests

These are in priority order:

   1. Resolve the current problem with GUMS not working with VOMS Admin 2.6 when a user has multiple DNs
   1. Scientific Linux 6 support for the worker node client by end of February, 2012 [[http://jira.opensciencegrid.org/browse/REQUESTS-16][REQUESTS-16]]
   1. Package GUMS and the Gratia collector (no timeline requested) [[http://jira.opensciencegrid.org/browse/REQUESTS-32][REQUESTS-32]] [[http://jira.opensciencegrid.org/browse/REQUESTS-34][REQUESTS-34]]
   1. Add CVMFS clients to the OSG Software Release
   1. Update Hadoop to the latest release.
   1. For any software that overlaps between EMI and OSG, we should review the version we are shipping to verify it is appropriate.

---+++ 3.2 ATLAS requests
ATLAS request are documented at: http://www.usatlas.bnl.gov/twiki/bin/view/Admins/OSGSoftwareRequests2012

Summary:
   1. Maintain the existing release and support users
   1. Scientific Linux 6 supportfor the worker node client by end of March, 2012 [[http://jira.opensciencegrid.org/browse/REQUESTS-16][REQUESTS-16]]
   1. !CREAM CE by September 2012 [[http://jira.opensciencegrid.org/browse/REQUESTS-33][REQUESTS-33]]
   1. CVMFS clients in the OSG Software release
   1. Support CEMon for the Storage Element

---+++ 3.3 Other requests

While there is not a unified request yet, it's clear that users need help in best practices for deploying their clients. We've had discussions with people from RENCI, ATLAS, and UCSD that all relate to this issue. How should people deploy in a cluster? (RPM vs. non-root installation on NFS) How should we mitigate the risks of using EPEL? 

