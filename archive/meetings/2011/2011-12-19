---+ OSG Software Team Meeting for 19-Dec-2011

---++ Attending
   * Cartwright, Tim
   * Gore, Brook
   * Kronenfeld, Scot
   * Potekhin, Maxim
   * Roy, Alain
   * Sharma, Neha
   * Selmeci, Mat
   * Sim, Alex

---++ Apologies
   * Sfiligoi, Igor
   * Strain, Doug

---++ Input on upcoming future changes

[[PossibleUpcomingWork][Some possible changes for future versions]]

Marco said that the osg-site-web-page needs to be updated. And it would be nice if osg-configure could configure it. 

No other suggestions were made and people were happy with the list as it stands.

---++ Mirror EPEL repositories?

We discussed a proposal from John Hover
<blockquote>
From: John Hover <jhover@bnl.gov>
Subject: Re: Getting ITB/testing sites up to date
Date: December 14, 2011 3:33:44 PM CST
To: Alain Roy <roy@cs.wisc.edu>
Cc: osg-int@OPENSCIENCEGRID.ORG, Chris Hollowell <hollowec@bnl.gov>

Hi Alain,

Xin and I have been talking about this issue. I'm not sure there is any way out of this, if the epel repo is used directly.

Is there any chance you might consider establishing stable mirrors of epel within the OSG repo? What I'm suggesting is that you create, for production, testing, and development, an "osg-epel" repo. The development osg-epel mirror can just be a normal mirror, with constant updates from the original. The testing epel mirror would be periodically frozen, based on its contents at a particular moment in time. After a period of testing (each month?) the epel testing mirror would be moved to epel production.

Incidentally, this would also greatly simplify the testing problems associated with the RPMs built for ATLAS requirements (LFC bindings, etc.). Rather than having to constantly test, we just have to ensure our RPMs are compatible with a static epel set.

This approach would allow all sites to always safely do "yum update" with almost no worry about incompatibilities introduced by an unexpected epel change. And it would integrate pretty easily with your current /etc/yum.repos.d/osg-*.repo setup (just add the [osg-epel] stanza in each file). The monthly repo migration would be a bit of a hassle, but I don't think it would be to onerous and could be automated.

What do you think? Would this really address all the current concerns, or would it leave a problem?

--john
</blockquote>

Tim's first question: what is the ongoing effort for it, and does it outweigh the benefits? It would be worth getting more details from users: how often have they seen breakage from EPEL? 

Suchandra thinks that sites have real concerns about not wanting unexpected updates from EPEL. For instance, the EPEL repository has Puppet, which sites may control separately. What happens when we move Globus back into EPEL?

Tim talked about how LIGO has Red Hat mirrors, and they ran into problems when the mirrors were out of date. So we have problems because we might be missing critical pieces that are in the origin. So we should investigate the deeper problem: in general, things change. How can we help site mitigate the risk without taking on a massive job. 

Marco points out that that previously some sites weren't using EPEL, so we are asking them to take on a new repository. 

Tim asked if we have access to a pre-release of EPEL. If so, should we test against upcoming versions of EPEL? 

---++ Likely changes in effort reporting for 2012

Our current effort reporting, while useful, does not help us answer all the questions we need to answer. Alain will be proposing concrete changes, but the likely upshot is that we'll report hours instead of percentages and we'll do it weekly instead of monthly. 

---++ Changes to how we version software

Mat's proposal from email:
<blockquote>
The following situation has come up a few times with some of our packages that we get as SRPMs from upstream and modify:

Upstream releases foobar-3.0-4. We patch it and call our version foobar-3.0-5.osg. We find another problem, patch it again, and call that version foobar-3.0-6.osg.

Then upstream releases their own foobar-3.0-5, and we pull it in. This causes problems in the changelog: since 3.0-5 came out after 3.0-6.osg, the entries would not be in chronological order.

I propose the following solution: instead of incrementing their release number, we will append our own. So when we patch foobar-3.0-4, we'll call our version foobar-3.0-4.1.osg. When we add another patch, we'll call our version foobar-3.0-4.2.osg. When upstream releases foobar-3.0-5, we'll patch it and call it foobar-3.0-5.1.osg. We should do this for all packages that we get as SRPMs and patch ourselves.
</blockquote>

Tim says it's a great idea. Tim wonders if it should be version-release.osg-OSGRELEASE instead of ver-release.OSGRELEASE.osg. Mat says that his proposal meets community standards better. TIm points out that there may be ambiguous situations where the division between "release" and "OSGRELEASE" isn't clear. 

---++ No meeting next two weeks

Due to the holidays, the next OSG Software Team meeting will be Monday January 9th, 2012.

---++ Status Reports

   * *Alex*: We have the new Bestman2 release! Alex believes it is really stable and fixes known problems with CA certificates (there was a recent ATLAS problem where it wasn't recognizing a particular CA, but upgrading an internal library solved the problem. The source code has been cleaned up and is up on the web. We can ask some questions as we go through the transition. What about hosting the source code at LBNL? We can't get commit access, but we can send patches to them. Research features should not be visible to users unless enabled. Ditto for the Bestman2 manual. 
   * *Igor*:  (via IM) "some glideinWMS testing and helping Soichi with scale testing BDII at GOC"
   * *Marco*: Working on documents (particularly VOMS) and the osg-site-web-page. Time on OSG Software will be decreasing for him to work on other things (like Campus Grids). There will be a meeting on this later today, and he'll update me.
   * *Mat*: osg-build is now 1.0, and there is a lot of documentation. Validating the Globus 5.2.0 final release. This is going well, but need to look at patches that will be removed. Should be one to two days of work. 
   * *Maxim*: Talked to Tim last Friday about adding new tests (for UberFTP and glexec) to the automated test suite. Working on it right now. 
   * *Neha*: Got the test stand working now. Have been trying to build the new Bestman2 code, will ask in the chat room.
   * *Scot*: Have not had much time for the OSG Software in the last week, but will have more time starting very soon.
   * *Suchandra*: Last week was working on Xrootd installation. Have been working on [[http://jira.opensciencegrid.org/browse/SOFTWARE-351][SOFTWARE-351]] (controlling SEG). Discovered -single option that improves memory and CPU of the gatekeeper. This might be useful to us.He'll talk to the Globus team about it as well.
   * *Terrence*: According to Igor, "Terrence was 100% dedicated to local ops last week"
   * *Tim*: Worked a lot on VOMS tests and problems with test cleanup. Coming along well. Almost to the point where the tests can run voms-proxy-init. 