---+ Meeting between Executive Team and OSG Software Coordinator, 7-April-2011

---++ Recently completed work

   1. We recently released a VDT update that addresses bugs in RSV. This culminates our effort to make usability improvements to RSV that will benefit site administrators. 

---++ Current work

   1. *Improved integration of software team*: We are taking concrete steps to ensure that the OSG Software Team is a single team, not the "VDT Team at Madison" and the "OSG Storage Group". In particular:
      1. *Team Meetings*: We have instituted whole-team meetings of the OSG Software Team. Previously we had separate meetings for UW-Madison folk and storage folk. They are every other week, with the smaller meetings happening on off-weeks. [[Meetings][Meeting Minutes]]
      1. *Shared Effort*: Historically, the VDT people from UW-Madison have done nearly all the packaging. Recently we have been training Tanya and Doug so that they can participate in packaging. They have focused on packaging of Xrootd, but I expect that will expand in the future. As knowledge spreads across the team, we will be able to use people more effectively.
      1. *Staffing and Effort*: Historically I have not had a good grasp of how we are spending our effort across the team. Recently we have been tracking effort in the VDT. We now have a spreadsheet that shows recent effort from everyone in the software team and some rough estimates for where effort will be spent in April and May.  [[%ATTACHURL%/VDTEffort.2011.04.06.xlsx][VDTEffort.2011.04.06.xlsx]]
   1. *Xrootd for ATLAS*: With ATLAS representatives (Michael Ernst, Doug Benjamin, Rob Gardner) we have agreed on the [[XrootdRPMPhase1Reqs][initial requirements for the Xrootd RPM]]. We have a "pass-through" RPM (see below) that implements most of their requirements, and we are working on the last details.
   1. *Worker Node RPMS*: We have completed an initial version of the worker node packed as binary RPMs. Last week it went to a few friendly testers and we have started to get some feedback from them. It appears to work correctly, but at least one site (Nebraska) can't use it as long it's incompatible with EPEL. [[WorkerNode][Worker Node plan]]
   1. *CREAM for ATLAS*: Our [[CREAM][first deliverable for CREAM]] is basic packaging with Pacman for testing purposes. Suchandra Thapa has been the main effort for resolving the remaining problems with this task, but he's gotten stuck due to strange errors we are getting from !CREAM. As of this week, Igor Sfiligoi joined Suchandra and is helping out. However, we still are unable to run a single !CREAM job. I spoke to John Hover this week and he says that due to hiring problems at BNL (see "GUMS" below), we have some slack in our schedule, so this delay is not a problem yet. Looking at question #2 below, should we consider a different approach to !CREAM using pass-through packaging? Alain recommends waiting on that decision to see how the current debugging goes, but we should consider this option within the next week if we continue having problems.
   1. *LIGO native packages*: LIGO recently requested some minor improvements to the packages we provide for them. We defined the requirements and have provided them with a test release. [[LIGOTweaks1][Requirements]].
   1. *GUMS*: John Hover _almost_ had a new developer to work on GUMS, but at the very last minute the developer declined the job. John has gotten up to speed on development and expect to give the VDT a new version this week. It's unclear if this is a long-term sustainable development plan (John is very busy), but for the moment we're okay. 
   1. *HadoopFS*: We are updating the !HadoopFS RPM repository we maintain for CMS (with assistance from Brian Bockelman). There have been problems, but we expect a new release soon. 

---++ Upcoming work

These are tasks we expect to work on in the near future. Planning for them is active, but no work has been done. 

   1. *GRAM improvements for CMS*: CMS has requested several improvements to GRAM. These are mostly configuration or extra tools outside of Globus proper, but one is a change that we will share with Globus. We are currently defining the requirements and we expect the changes to be in the next VDT release. 
   1. *Requirements management*: We have historically not done a good job of collecting, tracking, and prioritizing requirements and then setting plausible expectations for our stakeholders. The ABCD team (Alain, Brian, Chander, and Dan) is actively defining a process for requirements management. We will share it with the Executive Team when it is ready.
   1. *Distribution repositories*: We are developing a plan for a way for us to distribute software via the VDT that is externally contributed and may not have the same level of support, but we wish to provide it to our stakeholders via the VDT so that there is one place to go for software. !GlideinWMSVOFrontEnd is a candidate.
   1. *GlobusWorld 2011*: I will be giving a 15-minute invited talk on the VDT at !GlobusWorld. I intend to talk about how OSG uses Globus, with a focus on the various interesting ways that we have customized Globus for our use in the VDT and at individual sites. 

---++ Questions for the Executive Team 

   1. *Should we drop dCache packaging?* A few weeks ago, Tanya and I proposed that we should no longer provide VDT-specific packaging and configuration for major new versions of dCache. We're interested in your feedback. What do you think? Do you need more information from us? (A replica of our email to the ET is below.)
   1. We would like to change our approach to packaging software. Our proposal is connected to our native packaging efforts. Our question: is this a good enough idea that we should flesh out our proposal? [[CommunityPackagingProposal][Proposal for pass-through packaging]]

---++ Extra Background for dropping dCache packaging

A copy of the email to the Executive Team about dropping dCache packaging:

<pre>
To: osg-et@opensciencegrid.org
Date: March 10, 2011 10:24:22 AM CST
Subject: Request for feedback: drop dCache packaging

Hello,

For the last few years, the OSG Software Team has been repackaging
dCache for consumption by OSG users. We've got a distribution that
includes:

1. dCache RPMs
2. Extra software dCache uses (such as the postgresql database)
3. Custom configuration scripts we created to simplify the
installation and configuration of dCache.
4. Gratia transfer and storage probe RPMs, which we developed and
maintain
5. Community toolchest RPMs

We would like to propose that we no longer continue making or
distributing #1 - #3 for new major versions of dCache. We will
continue to provide gratia probes and community toolchest RPMs (#4 &
#5).

Our question for you: do you agree?

We propose this for two reasons:

A) Updates to major new versions (one of which is due this April) are
considerable effort.
B) According to our survey of OSG sites, almost no one in OSG uses
this packaging any more. We believe that our efforts to repackage
dCache provide a diminishing value and our effort is better spent
elsewhere.

What does "almost no one mean"? More precisely: 13 OSG sites use
dCache, and only 3 of them (UERJ, AGLT2, and IllinoisHEP) use the VDT
dCache installation.

We haven't contacted these three sites yet to see how inconvenient
this proposal is. We first want your approval that we are considering
the right general direction. If you agree, we'll work with the sites
to see how burdensome the transition is, and if we can help them with
it.

Thanks!
Alain & Tanya

</pre>
